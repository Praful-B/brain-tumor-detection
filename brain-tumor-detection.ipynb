{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dde2562e",
   "metadata": {},
   "source": [
    "# Brain tumor detection using a simple CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e4cd68",
   "metadata": {},
   "source": [
    "## Installing nessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7150a32-cb6e-4de4-94e2-c972a07e81b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.20.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.7.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.13/site-packages (from tensorflow) (25.0)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow)\n",
      "  Using cached protobuf-6.33.2-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./.venv/lib/python3.13/site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.venv/lib/python3.13/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-3.2.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in ./.venv/lib/python3.13/site-packages (from tensorflow) (4.15.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Using cached wrapt-2.0.1-cp313-cp313-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Using cached grpcio-1.76.0-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Using cached tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Using cached keras-3.12.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting numpy>=1.26.0 (from tensorflow)\n",
      "  Using cached numpy-2.3.5-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Using cached h5py-3.15.1-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.5.4-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached markdown-3.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pillow (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached pillow-12.0.0-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached werkzeug-3.1.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=3.10.0->tensorflow)\n",
      "  Using cached rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Using cached namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Using cached optree-0.18.0-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (34 kB)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in ./.venv/lib/python3.13/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.10.0->tensorflow)\n",
      "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.13/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Using cached tensorflow-2.20.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.8 MB)\n",
      "Using cached grpcio-1.76.0-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.6 MB)\n",
      "Using cached ml_dtypes-0.5.4-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "Using cached tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "Using cached absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Using cached flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Using cached gast-0.7.0-py3-none-any.whl (22 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached h5py-3.15.1-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.1 MB)\n",
      "Using cached keras-3.12.0-py3-none-any.whl (1.5 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "Using cached markdown-3.10-py3-none-any.whl (107 kB)\n",
      "Downloading numpy-2.3.5-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\u001b[0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Using cached protobuf-6.33.2-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "Using cached termcolor-3.2.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached werkzeug-3.1.4-py3-none-any.whl (224 kB)\n",
      "Using cached wrapt-2.0.1-cp313-cp313-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (121 kB)\n",
      "Using cached namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Using cached optree-0.18.0-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (414 kB)\n",
      "Using cached pillow-12.0.0-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
      "Using cached rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, werkzeug, termcolor, tensorboard-data-server, protobuf, pillow, optree, opt_einsum, numpy, mdurl, markdown, grpcio, google_pasta, gast, absl-py, tensorboard, ml_dtypes, markdown-it-py, h5py, astunparse, rich, keras, tensorflow\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27/27\u001b[0m [tensorflow]237m━\u001b[0m \u001b[32m26/27\u001b[0m [tensorflow]a]ver]\n",
      "\u001b[1A\u001b[2KSuccessfully installed absl-py-2.3.1 astunparse-1.6.3 flatbuffers-25.9.23 gast-0.7.0 google_pasta-0.2.0 grpcio-1.76.0 h5py-3.15.1 keras-3.12.0 libclang-18.1.1 markdown-3.10 markdown-it-py-4.0.0 mdurl-0.1.2 ml_dtypes-0.5.4 namex-0.1.0 numpy-2.3.5 opt_einsum-3.4.0 optree-0.18.0 pillow-12.0.0 protobuf-6.33.2 rich-14.2.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.2.0 werkzeug-3.1.4 wheel-0.45.1 wrapt-2.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80567786",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 19:04:54.796817: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-12 19:04:54.806754: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-12 19:04:55.410227: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-12 19:04:56.845644: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-12 19:04:56.845975: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6309eda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 19:05:07.757430: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus :\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)   \n",
    "    #Avoids the overuse of VRAM and prevents the Out Of Memory [OOM] Error !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af497922-8130-48e4-bec2-34a76b1cfce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./.venv/lib/python3.13/site-packages (2.3.5)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.8-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (52 kB)\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.3-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.61.0-cp313-cp313-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (113 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.9-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.13/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.13/site-packages (from matplotlib) (12.0.0)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.2.6-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Using cached matplotlib-3.10.8-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "Using cached opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (67.0 MB)\n",
      "Using cached numpy-2.2.6-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.5 MB)\n",
      "Using cached contourpy-1.3.3-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (362 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.61.0-cp313-cp313-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (4.9 MB)\n",
      "Using cached kiwisolver-1.4.9-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.5 MB)\n",
      "Using cached pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Installing collected packages: pyparsing, numpy, kiwisolver, fonttools, cycler, opencv-python, contourpy, matplotlib\n",
      "\u001b[2K  Attempting uninstall: numpy\n",
      "\u001b[2K    Found existing installation: numpy 2.3.5\n",
      "\u001b[2K    Uninstalling numpy-2.3.5:\n",
      "\u001b[2K      Successfully uninstalled numpy-2.3.5\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8/8\u001b[0m [matplotlib]\u001b[0m \u001b[32m7/8\u001b[0m [matplotlib]on]\n",
      "\u001b[1A\u001b[2KSuccessfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.61.0 kiwisolver-1.4.9 matplotlib-3.10.8 numpy-2.2.6 opencv-python-4.12.0.88 pyparsing-3.2.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy matplotlib opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c394d4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcv2\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimghdr\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import imghdr\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a3deb4",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634d022d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'Training'\n",
    "imgExts = ['jpeg', 'jpg', 'png', 'bmp', 'tiff']\n",
    "\n",
    "for imgCls in os.listdir(data) :  # This will return the list of the files inside the TRAINING folder, stored under the data var !\n",
    "    for img in os.listdir(os.path.join(data, imgCls)) :  # This will return the list of files inside each class folder !\n",
    "        imgPath = os.path.join(data,imgCls,img)\n",
    "        try :\n",
    "            imgType = imghdr.what(imgPath)   # This will return the image type if it's a valid image, else it returns None !\n",
    "            if imgType not in imgExts :      # If the image type is not in the list of valid image extensions !\n",
    "                print('Deleting : ', imgPath)\n",
    "                os.remove(imgPath)           # Delete the invalid image !\n",
    "        except Exception as e :\n",
    "            print('Error : ', e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801eee76",
   "metadata": {},
   "source": [
    "## Data Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b968d5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataS = tf.keras.utils.image_dataset_from_directory('Training')\n",
    "\n",
    "dataS_iterate = dataS.as_numpy_iterator()\n",
    "batch = dataS_iterate.next()\n",
    "\n",
    "fig, AX = plt.subplots(nrows=3, ncols=3, figsize=(5,5))\n",
    "for i in range(3) :\n",
    "    for j in range(3) :\n",
    "        AX[i,j].imshow(batch[0][i*3 + j].astype(int))\n",
    "        AX[i,j].axis('off')\n",
    "plt.show()\n",
    "\n",
    "dataS = dataS.map(lambda x,y: (x/255,y)) # Normalizing the images to the range [0,1]\n",
    "dataS = dataS.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "print(dataS)\n",
    "dataS_iterate = dataS.as_numpy_iterator()\n",
    "batch = dataS_iterate.next()\n",
    "# print(batch[0].max())  # Should print 1.0 after normalization\n",
    "# print(batch[0].min())  # Should print 0.0 after normalization\n",
    "# print(batch[1])      # Labels of the batch\n",
    "# print('Data Preparation Completed !')\n",
    "# print('Image Verification and Deletion of Corrupted Images Started !')\n",
    "# print('Data Preparation Started !')\n",
    "# print('Data Preparation Completed !')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6468eb3f",
   "metadata": {},
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728f61fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSize = int(len(dataS)*.7)\n",
    "valSize = int(len(dataS)*.2)\n",
    "testSize = int(len(dataS)*.1)\n",
    "\n",
    "print('Train Size : ', trainSize)\n",
    "print('Validation Size : ', valSize)\n",
    "print('Test Size : ', testSize)\n",
    "\n",
    "train = dataS.take(trainSize)\n",
    "val = dataS.skip(trainSize).take(valSize)\n",
    "test = dataS.skip(trainSize + valSize).take(testSize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e950b2e8",
   "metadata": {},
   "source": [
    "## Model Building\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46667df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# First Convolutional Block\n",
    "\n",
    "model.add(Conv2D(16, (3,3),1,activation = 'relu',padding = 'same',input_shape = (256,256,3)))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "# Second Convolutional Block\n",
    "model.add(Conv2D(32, (3, 3), 1, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "# Third Convolutional Block\n",
    "model.add(Conv2D(16, (3, 3), 1, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "# Flatten and Dense Layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(Dropout(0.5))   \n",
    "model.add(Dense(1, activation = 'sigmoid'))   # Signifies a YES/NO classification !\n",
    "\n",
    "# Model Compilation\n",
    "model.compile(optimizer = 'adam',loss = 'binary_crossentropy',metrics = ['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea474768",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4eafec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "\n",
    "longDir = 'logs'\n",
    "tensorboardCallBack = TensorBoard(log_dir = longDir)\n",
    "earlyStopping = EarlyStopping(monitor = 'val_loss',patience = 3,restore_best_weights = True)\n",
    "\n",
    "print(\"Initialized Model Training \")\n",
    "\n",
    "history = model.fit(train, epochs = 9, validation_data = val, callbacks = [tensorboardCallBack, earlyStopping])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1f0cc9",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047741aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test)\n",
    "print(f\"Test Loss - {loss}\\nTest Accuracy - {accuracy}\")\n",
    "\n",
    "# Plotting training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Plotting Training and Validation Accuracy and Loss\n",
    "axes[0].plot(history.history['accuracy'], label='Training Accuracy')\n",
    "axes[0].plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "axes[0].set_title('Model Accuracy')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "\n",
    "# Plot loss\n",
    "axes[1].plot(history.history['loss'], label='Training Loss')\n",
    "axes[1].plot(history.history['val_loss'], label='Validation Loss')\n",
    "axes[1].set_title('Model Loss')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Saving the model\n",
    "model.save('deMLon_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe76017",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14061f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictTumor(imgPath, model):\n",
    "    \"\"\"Predict if an image has tumor and return results\"\"\"\n",
    "    img = cv2.imread(imgPath)\n",
    "    if img is None: \n",
    "        print(\"Error: Unable to read image at\", imgPath)\n",
    "        return None, 0.0\n",
    "    \n",
    "    img = cv2.resize(img, (256, 256))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img / 255.0   # Image Normalization\n",
    "    img = np.expand_dims(img, axis=0)  # Expanding dimensions\n",
    "    \n",
    "    prediction = model.predict(img, verbose=0)  \n",
    "    confidence = float(prediction[0][0])\n",
    "    \n",
    "    if confidence > 0.5:\n",
    "        result = \"TUMOR DETECTED\"\n",
    "        conf_display = confidence * 100\n",
    "    else:\n",
    "        result = \"NO TUMOR\"\n",
    "        conf_display = (1 - confidence) * 100\n",
    "    \n",
    "    return result, conf_display, confidence\n",
    "\n",
    "def visualizePrediction(imgPath, model):  # Added model parameter\n",
    "    \"\"\"Visualize prediction results\"\"\"\n",
    "    result, conf_display, confidence = predictTumor(imgPath, model)\n",
    "    \n",
    "    if result is None:  # Handle error case\n",
    "        return None, None\n",
    "    \n",
    "    img = cv2.imread(imgPath)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"{result}\\nConfidence: {conf_display:.2f}%\", \n",
    "              fontsize=14, fontweight='bold')  # Fixed typo\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return result, conf_display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9ca116",
   "metadata": {},
   "source": [
    "## Prediction testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdf48ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "testImgPath = input(\"Enter the image path: \")\n",
    "if os.path.exists(testImgPath): \n",
    "    print(\"Analyzing:\", testImgPath)\n",
    "    \n",
    "    result, conf_display = visualizePrediction(testImgPath, model)  # Added model\n",
    "    \n",
    "    if result:  # Check if result is valid\n",
    "        print(f\"Prediction: {result} with confidence of {conf_display:.2f}%\")\n",
    "else:\n",
    "    print(\"The provided image path does not exist. Please check and try again.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
